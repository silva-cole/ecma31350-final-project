{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67e990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, log_loss\n",
    "import sklearn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import hist\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c31a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for numpy\n",
    "RANDOM_SEED=42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b0d275",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ATT and ATE AIPTW\n",
    "def att_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    Double ML estimator for the ATT\n",
    "    This uses the ATT specific scores, see equation 3.9 of https://www.econstor.eu/bitstream/10419/149795/1/869216953.pdf\n",
    "    Return: aiptw of ATE and its standard error\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of observations\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # estimate marginal probability of treatment\n",
    "    if prob_t is None:\n",
    "        prob_t = A.mean() \n",
    "    \n",
    "    # att aiptw\n",
    "    tau_hat = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0)).mean()/ prob_t\n",
    "  \n",
    "    # influence curve and standard error of aiptw\n",
    "    phi = (A*(Y-Q0) - (1-A)*(g/(1-g))*(Y-Q0) - tau_hat*A) / prob_t\n",
    "    std_hat = np.std(phi) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat\n",
    "\n",
    "def ate_aiptw(Q0, Q1, g, A, Y, prob_t=None):\n",
    "    \"\"\"\n",
    "    Double ML estimator for the ATE\n",
    "    Return: aiptw of ATE and its standard error\n",
    "    \"\"\"\n",
    "    # number of observations\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # ate aiptw\n",
    "    tau_hat = (Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g)).mean()\n",
    "  \n",
    "    # influence curve and standard error of aiptw\n",
    "    phi = Q1 - Q0 + A*(Y-Q1)/g - (1-A)*(Y-Q0)/(1-g) - tau_hat   \n",
    "    std_hat = np.std(phi) / np.sqrt(n)\n",
    "\n",
    "    return tau_hat, std_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be19d4b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Conditional outcome models (Q models)\n",
    "def make_linear_Q_model():\n",
    "    ''' A function that returns a linear q model for later use in k-folding'''\n",
    "    return LinearRegression()\n",
    "\n",
    "def make_Q_model(output_type:str):\n",
    "    ''' A function that returns a general ML q model for later use in k-folding'''\n",
    "    if output_type == 'binary':\n",
    "        return RandomForestClassifier(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
    "    return RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)\n",
    "# One example: RandomForestRegressor(random_state=RANDOM_SEED, n_estimators=500, max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cf517f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Propensity score models (g models)\n",
    "def make_g_model():\n",
    "    ''' A function that returns a g model for computing propensity scores'''\n",
    "    return RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "# One example: RandomForestClassifier(n_estimators=100, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52dee72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Functions for K-fold cross-fitting\n",
    "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    '''\n",
    "\n",
    "    predictions = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, A):\n",
    "        X_train = X.loc[train_index]\n",
    "        A_train = A.loc[train_index]\n",
    "        g = make_model()\n",
    "        g.fit(X_train, A_train)\n",
    "\n",
    "        # get predictions for split\n",
    "        predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "    \n",
    "    # sanity check that overlap holds\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    y: array of outcomes\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "    '''\n",
    "\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_w_treatment = X.copy()\n",
    "    X_w_treatment[\"A\"] = A\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_w_treatment.copy()\n",
    "    X0[\"A\"] = 0\n",
    "    X1 = X_w_treatment.copy()\n",
    "    X1[\"A\"] = 1\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
    "        X_train = X_w_treatment.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        q = make_model(output_type)\n",
    "        q.fit(X_train, y_train)\n",
    "\n",
    "        if output_type =='binary':\n",
    "            predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
    "            predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
    "        elif output_type == 'continuous':\n",
    "            predictions0[test_index] = q.predict(X0.loc[test_index])\n",
    "            predictions1[test_index] = q.predict(X1.loc[test_index])\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "129b3b92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_and_run_model(df, outcome:str, treatment:str, confounders:list, make_g_model,\n",
    "                      make_Q_model, n_splits=5, output_type='binary', ate=True):\n",
    "    '''\n",
    "    Function that creates a g, q, and aiptw model based on the \n",
    "    given inputs\n",
    "    \n",
    "    Inputs: df (pandas df) - the dataframe the variables are contained in\n",
    "            outcome (str) - the outcome variable\n",
    "            treatment (str) - the treatment variable\n",
    "            confounders (lst) - a list of the confounding variables\n",
    "            make_g_model - the make_g_model function\n",
    "            make_Q_model - the make_Q_model function\n",
    "            n_splits (int) - number of splits for the model\n",
    "            output_type (str) - the desired output type, either binary or continous\n",
    "            ate (bool) - whether to use ate or alternative att\n",
    "    \n",
    "    Returns: tau_hat - the tau hat estimator for the average treatment effect\n",
    "             std of tau_hat - the standard deviation for the tau_hat estimator\n",
    "    '''\n",
    "    df = df.replace({outcome: .00001}, 0)\n",
    "    df = df[[outcome] + confounders + [treatment]]\n",
    "    df = df.dropna().reset_index()\n",
    "    print('Running models for treatment {} and outcome {} on {} samples'.format(treatment, outcome, len(df)))\n",
    "\n",
    "    outcome = df[outcome]\n",
    "    confounders = df[confounders]\n",
    "    treatment = df[treatment]\n",
    "    treatment = treatment.replace({0.0: 0, 1.0: 1})\n",
    "    outcome = outcome.replace({0.0: 0, 1.0: 1})\n",
    "    g = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=n_splits)\n",
    "    drop=False\n",
    "    if min(g) < .01:\n",
    "        print('\\nWARNING:\\n Some propensity scores are very small,\\n which could '\n",
    "              'lead to an inflated AIPTW.\\n Minimum score = ', min(g))\n",
    "        drop = True\n",
    "    if max(g) > .99:\n",
    "        print('\\nWARNING:\\n Some propensity scores are very large,\\n which could '\n",
    "              'lead to an inflated AIPTW.\\n Maximum score = ', max(g))\n",
    "        drop = True\n",
    "    print('G Model has been fit')\n",
    "\n",
    "    Q0_ml, Q1_ml = outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, \\\n",
    "                                                  n_splits=n_splits, output_type=output_type)\n",
    "    \n",
    "    print('Q model has been fit')\n",
    "    data_and_nuisance_estimates_ml = pd.DataFrame({'g': g, 'Q0': Q0_ml, 'Q1': Q1_ml, 'A': treatment, 'Y': outcome})\n",
    "    \n",
    "    if drop:\n",
    "        data_and_nuisance_estimates_ml = data_and_nuisance_estimates_ml[data_and_nuisance_estimates_ml['g'] > .01]\n",
    "        data_and_nuisance_estimates_ml = data_and_nuisance_estimates_ml[data_and_nuisance_estimates_ml['g'] < .99]\n",
    "        print('Dropped {} observations due to overlap condition'.format(len(df) - len(data_and_nuisance_estimates_ml)))\n",
    "    n = len(data_and_nuisance_estimates_ml)\n",
    "    # ate aiptw\n",
    "    if ate:\n",
    "        tau_hat, std_hat = ate_aiptw(**data_and_nuisance_estimates_ml)\n",
    "    else: \n",
    "        tau_hat, std_hat = att_aiptw(**data_and_nuisance_estimates_ml)\n",
    "    test_stat = tau_hat / std_hat\n",
    "    p_value = stats.t.sf(abs(test_stat), df=(n-1))\n",
    "    print('AIPTW model has been fit. Returning \\u03C4 hat and its standard error')\n",
    "    print('\\u03C4 hat = {}, std = {}, test statistic = {}, p-value = {}\\n'.format(round(tau_hat, 5), round(std_hat, 5), round(test_stat, 5), round(p_value, 5)))\n",
    "    return tau_hat, std_hat, test_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18d6ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_df = pd.read_csv(\"../data/final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4f76c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'lname', 'fname', 'key', 'rank', 'status',\n",
       "       'tenure', 'emeritus', 'year', 'nationality', 'university', 'psych',\n",
       "       'esfellow', 'indian', 'otherasian', 'jewish', 'indian2', 'otherasian2',\n",
       "       'jewish2', 'nobel', 'clark', 'first_letter', 'letter_as_number',\n",
       "       'nobel_or_clark', 'letter_binarized'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faculty_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a1eb54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = \"tenure\"\n",
    "treatment = \"letter_binarized\"\n",
    "confounders = [\"indian\",\n",
    "               \"otherasian\",\n",
    "               \"jewish\",\n",
    "               \"rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a49087f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running models for treatment letter_binarized and outcome tenure on 218 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = -0.07492, std = 0.08743, test statistic = -0.85697, p-value = 0.1962\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 426 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = -0.07633, std = 0.04671, test statistic = -1.6341, p-value = 0.05149\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 1011 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = -0.003, std = 0.02961, test statistic = -0.10132, p-value = 0.45966\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 1305 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = -0.0158, std = 0.02555, test statistic = -0.61857, p-value = 0.26815\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 435 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = 0.13795, std = 0.1153, test statistic = 1.19648, p-value = 0.11608\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 624 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = 0.07259, std = 0.05904, test statistic = 1.22959, p-value = 0.10966\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 1260 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = -0.01034, std = 0.02394, test statistic = -0.43183, p-value = 0.33297\n",
      "\n",
      "Running models for treatment letter_binarized and outcome tenure on 1685 samples\n",
      "G Model has been fit\n",
      "Q model has been fit\n",
      "AIPTW model has been fit. Returning τ hat and its standard error\n",
      "τ hat = -0.01223, std = 0.01951, test statistic = -0.62674, p-value = 0.26546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dict = {'psych': [], 'ranking_cap': [], \n",
    "           'tau': [], 'tau_stderr': [], \n",
    "           'test_stat': [], 'p_value': []}\n",
    "for psych in [0, 1]:\n",
    "    for ranking_cap in [5, 10, 25, 35]:\n",
    "        sample_df = faculty_df[faculty_df['psych'] == psych]\n",
    "        tau, tau_stderr, test_stat, p_value = fit_and_run_model(sample_df[sample_df['rank'] <= ranking_cap], \\\n",
    "                                                                outcome, treatment, confounders, make_g_model, \\\n",
    "                                                                make_Q_model)\n",
    "        \n",
    "        df_dict['psych'].append(psych)\n",
    "        df_dict['ranking_cap'].append(ranking_cap)\n",
    "        df_dict['tau'].append(tau)\n",
    "        df_dict['tau_stderr'].append(tau_stderr)\n",
    "        df_dict['test_stat'].append(test_stat)\n",
    "        df_dict['p_value'].append(p_value)\n",
    "\n",
    "results_df = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89af7958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>psych</th>\n",
       "      <th>ranking_cap</th>\n",
       "      <th>tau</th>\n",
       "      <th>tau_stderr</th>\n",
       "      <th>test_stat</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.074923</td>\n",
       "      <td>0.087428</td>\n",
       "      <td>-0.856968</td>\n",
       "      <td>0.196204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.076332</td>\n",
       "      <td>0.046712</td>\n",
       "      <td>-1.634099</td>\n",
       "      <td>0.051489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>0.029607</td>\n",
       "      <td>-0.101320</td>\n",
       "      <td>0.459658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.015804</td>\n",
       "      <td>0.025549</td>\n",
       "      <td>-0.618573</td>\n",
       "      <td>0.268153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.137955</td>\n",
       "      <td>0.115301</td>\n",
       "      <td>1.196480</td>\n",
       "      <td>0.116081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.072592</td>\n",
       "      <td>0.059038</td>\n",
       "      <td>1.229592</td>\n",
       "      <td>0.109657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>-0.431825</td>\n",
       "      <td>0.332971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.012227</td>\n",
       "      <td>0.019509</td>\n",
       "      <td>-0.626739</td>\n",
       "      <td>0.265458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   psych  ranking_cap       tau  tau_stderr  test_stat   p_value\n",
       "0      0            5 -0.074923    0.087428  -0.856968  0.196204\n",
       "1      0           10 -0.076332    0.046712  -1.634099  0.051489\n",
       "2      0           25 -0.003000    0.029607  -0.101320  0.459658\n",
       "3      0           35 -0.015804    0.025549  -0.618573  0.268153\n",
       "4      1            5  0.137955    0.115301   1.196480  0.116081\n",
       "5      1           10  0.072592    0.059038   1.229592  0.109657\n",
       "6      1           25 -0.010336    0.023936  -0.431825  0.332971\n",
       "7      1           35 -0.012227    0.019509  -0.626739  0.265458"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bcd732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
